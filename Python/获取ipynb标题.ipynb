{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb0629aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../in_dir/69. Vizualizing convnet filters.ipynb', '../../in_dir/A first look at a neural network.ipynb', '../../in_dir/Advanced_usage_of_recurrent_neural_networks.ipynb', '../../in_dir/Aggregation and Grouping.ipynb', '../../in_dir/Aggregations - Min, Max, and Everything In Between.ipynb', '../../in_dir/Application - A Face Detection Pipeline.ipynb', '../../in_dir/Backward_and_forward_pass_using_pytorch.ipynb', '../../in_dir/Basics of Neural Network.ipynb', '../../in_dir/Bidirectional_RNNs_on_IMDB_Data.ipynb', '../../in_dir/Binary Classification of Cancer Data.ipynb', '../../in_dir/Classifying movie reviews - A binary classification.ipynb', '../../in_dir/Classifying Text using Multinomial Naive Bayes.ipynb', '../../in_dir/Combining Datasets - Concat and Append.ipynb', '../../in_dir/Combining Datasets - Merge and Join.ipynb', '../../in_dir/Combining_CNNs_and_RNNs_to_process_long_sequences.ipynb', '../../in_dir/Comparisons, Masks, and Boolean Logic.ipynb', '../../in_dir/Computation on Arrays -  Broadcasting.ipynb', '../../in_dir/Computation on NumPy Arrays - Universal Functions.ipynb', '../../in_dir/Concepts behind convnets.ipynb', '../../in_dir/convnets with small datasets.ipynb', '../../in_dir/Customizing Colorbars.ipynb', '../../in_dir/Customizing Matplotlib - Configurations and Stylesheets.ipynb', '../../in_dir/Customizing Plot Legends.ipynb', '../../in_dir/Customizing Ticks.ipynb', '../../in_dir/Data Indexing and Selection.ipynb', '../../in_dir/Data Loading and Processing Tutorial.ipynb', '../../in_dir/Data Manipulation with Pandas.ipynb', '../../in_dir/Data preprocessing for neural networks.ipynb', '../../in_dir/Deep Learning - Introduction & Tensorflow - Basics.ipynb', '../../in_dir/Density and Contour Plots.ipynb', '../../in_dir/Example - k-Nearest Neighbours.ipynb', '../../in_dir/Face Recognition Using Support Vector Machines.ipynb', '../../in_dir/Fancy Indexing.ipynb', '../../in_dir/Feature Engineering.ipynb', '../../in_dir/Feature selection for Multiple Linear Regression.ipynb', '../../in_dir/Fine tuning using pretrained convnet.ipynb', '../../in_dir/GANs_in_keras.ipynb', '../../in_dir/Geographic Data with Basemap.ipynb', '../../in_dir/gloVe.ipynb', '../../in_dir/Gradient-based optimization.ipynb', '../../in_dir/Handling Missing Data.ipynb', '../../in_dir/Hierarchical Indexing.ipynb', '../../in_dir/High-Performance Pandas - eval() and query().ipynb', '../../in_dir/Histograms, Binnings, and Density.ipynb', '../../in_dir/Hyperparameters and Model Validation.ipynb', '../../in_dir/In Depth - Gaussian Mixture Models.ipynb', '../../in_dir/In Depth - k-Means Clustering.ipynb', '../../in_dir/In Depth - Linear Regression II.ipynb', '../../in_dir/In Depth - Linear Regression.ipynb', '../../in_dir/In Depth - Naive Bayes Classification.ipynb', '../../in_dir/In-Depth - Decision Trees.ipynb', '../../in_dir/In-Depth - Manifold Learning.ipynb', '../../in_dir/Introducing Pandas Objects.ipynb', '../../in_dir/Introducing Scikit Learn.ipynb', '../../in_dir/Introduction to convnets.ipynb', '../../in_dir/Keras Callbacks.ipynb', '../../in_dir/Keras_Functional_API.ipynb', '../../in_dir/Linear Regression using gradient descent.ipynb', '../../in_dir/Machine Learning - Overview.ipynb', '../../in_dir/Matplotlib - Intro.ipynb', '../../in_dir/Medical Appointments No Show - Dataset.ipynb', '../../in_dir/Methods using regular expressions.ipynb', '../../in_dir/MNIST_CNN.ipynb', '../../in_dir/MNIST_DCGAN.ipynb', '../../in_dir/Model Training.ipynb', '../../in_dir/Multiple Subplots.ipynb', '../../in_dir/Naive Bayes Classifier.ipynb', '../../in_dir/Neural_Style_Transfer.ipynb', '../../in_dir/NLP_Using_CLTK.ipynb', '../../in_dir/Numpy and Torch.ipynb', '../../in_dir/Numpy.ipynb', '../../in_dir/Operating on Data in Pandas.ipynb', '../../in_dir/Overfitting and underfitting.ipynb', '../../in_dir/PCA.ipynb', '../../in_dir/Pivot Tables.ipynb', '../../in_dir/Playing with GOOG.ipynb', '../../in_dir/Random Forests.ipynb', '../../in_dir/Regularization methods to IMDb movie dataset.ipynb', '../../in_dir/Simple Line Plots.ipynb', '../../in_dir/Simple Linear Regression.ipynb', '../../in_dir/Sorting Arrays.ipynb', \"../../in_dir/Structured Data - NumPy's Structured Arrays.ipynb\", '../../in_dir/Support Vector Machines.ipynb', '../../in_dir/Taxi.ipynb', '../../in_dir/Tensor Operation.ipynb', '../../in_dir/Tensorboard.ipynb', '../../in_dir/Text and Annotation.ipynb', '../../in_dir/Text_generation_using_LSTM.ipynb', '../../in_dir/The Boston Dataset.ipynb', '../../in_dir/The Reuters dataset.ipynb', '../../in_dir/Three-Dimensional Plotting in Matplotlib.ipynb', '../../in_dir/Titanic.ipynb', '../../in_dir/Torch activations.ipynb', '../../in_dir/Torch Variable.ipynb', '../../in_dir/Unsupervised learning example - Iris dimensionality.ipynb', '../../in_dir/Variational_Autoencoders.ipynb', '../../in_dir/Vectorized String Operations.ipynb', '../../in_dir/Visualization with Seaborn.ipynb', '../../in_dir/Visualizing Errors.ipynb', '../../in_dir/Visualizing what convnets learn.ipynb', '../../in_dir/Visualizing_heatmaps_of_class_activation.ipynb', '../../in_dir/Viz Seattle Bicycle Counts.ipynb', '../../in_dir/With data argumentation.ipynb', '../../in_dir/Without data argumentation.ipynb', '../../in_dir/Word_embeddings.ipynb', '../../in_dir/Working with Time Series.ipynb']\n",
      "106\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "path_li = []\n",
    "dir_in = '../../in_dir'\n",
    "for root, dirs, files in os.walk(dir_in):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith('.ipynb'):\n",
    "            file_path = os.path.join(root, file_name)\n",
    "            path = file_path.replace('\\\\', '/')\n",
    "            path_li.append(path)\n",
    "print(path_li)\n",
    "print(len(path_li))\n",
    "\n",
    "out_dir = '../../out_dir'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "\n",
    "for name in path_li:\n",
    "    with open(name, encoding='utf8') as f:\n",
    "        text = json.load(f)\n",
    "\n",
    "    out_path = out_dir + '/' + name.split('/')[-1]\n",
    "    out_path = out_path.replace('ipynb', 'txt')\n",
    "    with open(out_path, 'w', encoding='utf8') as f:\n",
    "        a = text['cells'][0]['source'][0]\n",
    "        s = a.replace('# ', '')\n",
    "        f.writelines(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
